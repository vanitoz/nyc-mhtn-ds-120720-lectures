{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Prep for Mod 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from math import sqrt\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import sklearn "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img desktop=\"normal_table\" style=\"withd:300px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img Documents/Flatiron=\"hypo_test.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('XXX.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "Glossary of Terms\n",
    "\n",
    "Standard Z-Score - n > 30, pop. std. dev. is known\n",
    "\n",
    "One Sample Z-Test - comparing one sample to the mean, and means same quals. as Std. \n",
    "Z-Score as part of Population\n",
    "\n",
    "Two Sample Z-Test - comparing two sample mean to each other, and has same quals. as Std. Z-Score. Z-Score as part of Population\n",
    "\n",
    "Two Proportion Z-Test - comparing two proportions to each other\n",
    "\n",
    "Population Probability Test - comparing two population samples\n",
    "\n",
    "One Sample T-Test - comparing one sample to the mean, & do not have pop. std. dev.\n",
    "\n",
    "Two Sample T-Test - comparing two sample to the mean, & do not have pop. std. dev.\n",
    "\n",
    "Confidence Interval Function - Find the range between the lower margin of error and higher.\n",
    "\n",
    "Using PPF and CDF to get P-values and T-crit\n",
    "\n",
    "Linear Regression Models - \"Relationship\" between two quantitative variables, looking for coef. Looking to evaluate the P > |t|. The greater the P value, the lower the correlation.\n",
    "\n",
    "Data Cleaning Process\n",
    "\n",
    "Bayesian Approach\n",
    "\n",
    "Type I & II Error\n",
    "\n",
    "Graph to Visualize Rejection Region"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Glossary of terms\n",
    "### ðœ‡ - \n",
    "the mean\n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### ðœŽ - \n",
    "the population standard deviation. The difference between population std. dev. and sample std. dev. is denoted as a \"s\".\n",
    "\n",
    "Look for explicit phrasing about what exactly is the whole (population). If there is no whole sample to draw from, it is a sample population. \n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### population - \n",
    "the collection of all the items of interest in a study (omega) the whole universe of things we are talking about\n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### sample -  \n",
    "a subset of the population \n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### subset - \n",
    "all the items that are in the population but in a specific group. A proper subset is some of the elements but not all of them\n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### p-value - \n",
    "The probability of getting a result at least as extreme as the sample  assuming the null hypothesis is true. \n",
    "\n",
    "Assuming you null hypothesis is true what are the chance this (or something at least this extreme) even occurred. \n",
    "\n",
    "For example, imagine your null hypothesis ð»0 is that the population mean ðœ‡ is ðœ‡=10. Upon drawing\n",
    "a sample, you get a mean of 12. With the p-value, you are going to obtain a probability that,\n",
    "given a null hypothesis of ðœ‡=10, you would observe a sample mean of 12.\n",
    "\n",
    "If your p-value is low, you will reject your null hypothesis. \n",
    "You will basically say that based on current evidence and testing, \n",
    "the null hypothesis is not true.\n",
    "\n",
    "If your p-value is high, you will fail to reject your null hypothesis. \n",
    "You will fail to reject the null hypothesis, \n",
    "that is, you will say that based on current evidence and testing, \n",
    "the null hypothesis cannot be rejected.\n",
    "\n",
    "If your p-value is low, you say that that the result is significant, in the sense \n",
    "that you conclude that the sample mean is significantly different from the population mean.\n",
    "\n",
    "_______________________________________________\n",
    "\n",
    "### Significance Threshold (alpha, ð›¼) - \n",
    "\n",
    "You noticed that we talked about \"high\" and \"low\" p-values, but that is pretty vague. \n",
    "What number is high and what number is low?\n",
    "\n",
    "This is where the significance level, also denoted as alpha or ð›¼ comes in. \n",
    "ð›¼ is the threshold value that defines whether a p-value is low or high. \n",
    "You can define your alpha level yourself, but you'll see that an alpha level of \n",
    "ð›¼=0.05 is most commonly used. You'll see ð›¼=0.1 and ð›¼=0.01 appear frequently as well.\n",
    "\n",
    "What level of alpha to use depends on your situation. Choosing a lower alpha leads to a test\n",
    "that is more strict, so you will be less likely to be able to reject your null-hypothesis \n",
    "(which is generally what you want). Choosing a higher alpha or significance level leads to \n",
    "a higher probability of rejecting the null-hypothesis. The downside of using a higher alpha\n",
    "level, however, is that you run a higher risk of falsely concluding that there is a difference\n",
    "between your null-hypothesis and your observed results when there actually isn't any.\n",
    "\n",
    "If p-value > alpha --> we fail to reject Null Hypothesis\n",
    "\n",
    "if p-value < alpha --> we reject Null Hypothesis\n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### T-Critical -\n",
    "\n",
    "For one samples. Right tailed. If your t-value is greater than your t-crit you will reject your null hypothesis and if it is less than your t-crit you will fail to reject your null hypothesis.\n",
    "Because it is right tailed only the first 2 of the examples apply.\n",
    "If left tailed the last 2 of the examples apply. \n",
    "Remember that if single tailed, the alpha will not be divided.\n",
    "\n",
    "Specifically for a 2 sided test, remember to divide alpha by 2, with each half in both tails. When our test statistic value, (z or t score) greater or less than t-critical value we can reject \n",
    "\n",
    "if t-value > t-critical --> we reject Null Hypothesis\n",
    "\n",
    "if t-value < t-critical --> we fail to reject Null Hypothesis\n",
    "\n",
    "if -t-value < -t-critical --> we reject Null Hypothesis\n",
    "\n",
    "if -t-value > -t-critical --> we fail to reject Null Hypothesis\n",
    "\n",
    "\n",
    "________________________________________________\n",
    "\n",
    "### Linear Regression - \n",
    "\n",
    "Linear regression is a statistical methodology that estimates the strength between two or more\n",
    "variables. The regression results show if the relationship is valid or not.\n",
    "\n",
    "Regression Analysis is a parametric technique meaning a set of parameters are used to predict the value of an unknown target variable (or dependent variable)  based on one or more of known input features (or independent variables, predictors), often denoted by \n",
    "\n",
    "In general, regression analysis helps us in the following ways:\n",
    "* Finding an association or relationship between certain phenomena or variables\n",
    "* Identifying which variables contribute more towards the outcomes\n",
    "* Prediction of future observations\n",
    "\n",
    "Simple Linear Regression - uses a single feature (one independent variable) to model a linear relationship with a target (the dependent variable) by fitting an optimal model\n",
    "\n",
    "Multiple Linear Regression uses more than one feature to predict a target variable by fitting the best linear relationship.\n",
    "\n",
    "Slope and Intercept are the coefficients or the parameters of a linear regression model.\n",
    "\n",
    "* If we see 'relationship' in a question we can assume \"Simple Linear Regression\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GMoneyMan\\anaconda3\\envs\\learn-env\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu, sigma = 0.5, 0.1\n",
    "n = 1000\n",
    "s = np.random.normal(mu, sigma, n)\n",
    "sns.distplot(s);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "What do you do if we aren't given an alpha, how do we reject or fail to reject. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List of Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Z-score\n",
    "The standard score (more commonly referred to as a ð‘§-score) \n",
    "is a very useful statistic because it allows us to:\n",
    "\n",
    "1) Calculate the probability of a certain score occurring within a given normal distribution\n",
    "\n",
    "2) Compare two scores that are from different normal distributions.\n",
    "\n",
    "Any normal distribution can be converted to a standard normal distribution and vice versa using this equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (x - ðœ‡) / ðœŽ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ð‘¥ is an observation from the original normal distribution\n",
    "\n",
    "ðœ‡ is the mean \n",
    "\n",
    "ðœŽ is the standard deviation of the original normal distribution.\n",
    "\n",
    "The standard normal distribution is sometimes called the ð‘§-distribution. \n",
    "\n",
    "A ð‘§-score always reflects the number of standard deviations above or below the mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Z-Score examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute and interpret the z-score for a tree yielding 35 pounds of apples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = df.mean()\n",
    "sd = df.std()\n",
    "mean,sd\n",
    "\n",
    "#the mean value is 42.4 and the standard deviation is around 6\n",
    "# 68% of tree yields have weight between (42.4 - 6) 36.4 and (42.4 - 6) 48.4 pounds; \n",
    "# 95% between 30.4 and 54.4; \n",
    "# Almost all between 24.4 and 60.4 pounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (35 - mean)/std\n",
    "z\n",
    "\n",
    "# -1.233844\n",
    "\n",
    "# Interpret the result\n",
    "\n",
    "# This treeâ€™s yield is 1.23 standard deviations below the mean yield."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose a tree has a z-score of 1.85. Interpret this z-score. What is the yield of this tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpret the z score\n",
    "\n",
    "# This treeâ€™s yield is 1.85 standard deviations above the mean\n",
    "\n",
    "X = mean + 1.85*sd\n",
    "X\n",
    "\n",
    "# Yield of this tree is 53.5 pounds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample z-test  \n",
    "Import numpy as np \n",
    "\n",
    "from  scipy import stats \n",
    "\n",
    "stats.ttest_1samp(TestSample1, popmean=0) \n",
    "\n",
    "_______________________________________________________________\n",
    "\n",
    "The one-sample ð‘§-test is used when you want to know \n",
    "\n",
    "if your sample comes from a particular population.\n",
    "\n",
    "The one-sample ð‘§-test is used only for tests related to the sample mean.\n",
    "\n",
    "When running a one-sample z-test, you test whether the average of the sample \n",
    "\n",
    "suggests that the students come from a certain population with a known mean or \n",
    "\n",
    "whether it may come from a different population.\n",
    "\n",
    "You already know what a ð‘§-score is and how to standardize a dataset into a ð‘§-distribution. \n",
    "\n",
    "By itself, the ð‘§-score doesn't provide a lot of information to conclude a question \n",
    "\n",
    "significantly (except for saying how many standard deviations some observation is from a mean).\n",
    "\n",
    "The real value from a ð‘§-test comes from comparing it against a z-table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One sample z-test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from math import sqrt\n",
    "x_bar = 103 # sample mean \n",
    "n = 40 # number of students\n",
    "sigma = 16 # sd of population\n",
    "mu = 100 # Population mean \n",
    "\n",
    "z = (x_bar - mu)/(sigma/sqrt(n))\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using the stats function we can find the p value from the z value we find.\n",
    "z = 1.19\n",
    "stats.norm.cdf(z)\n",
    "\n",
    "-> 0.8821600432854813\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The percent area under the curve from to a ð‘§-score of 1.19 is 88.2% (using the ð‘§-table \n",
    "or SciPy calculations), this means that the average intelligence of the tutored set of \n",
    "students is bigger than 88.2% of the population. But with alpha specified as 0.05, \n",
    "we wanted it to be greater than 95% to prove the hypothesis to be significant.\n",
    "\n",
    "Mathematically, you want to get the p-value, and this can be done by subtracting the \n",
    "ð‘§-value from 1, since the sum of probabilities is always 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval = 1 - stats.norm.cdf(z)\n",
    "pval\n",
    "\n",
    "-> 0.11783995671451875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "our alpha is 0.05 and our p-value is 0.12. We can fail to reject our Null Hypothesis because our p-value \n",
    "is greater than alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our p-value (0.12) is larger than the alpha of 0.05. So what does that mean? \n",
    "Can you not conclude that tutoring leads to an IQ increase?\n",
    "\n",
    "Well, you still can't really say that for sure. What we can say is that there is not enough \n",
    "evidence to reject the null hypothesis with the given sample, given an alpha of 0.05. \n",
    "There are ways to scale experiments up and collect more data or apply sampling techniques \n",
    "to be sure about the real impact.\n",
    "\n",
    "And even when the sample data helps to reject the null hypothesis, you still cannot be 100% \n",
    "sure of the outcome. What you can say, however, is given the evidence, the results show a \n",
    "significant increase in the IQ as a result of tutoring, instead of saying \"tutoring improves IQ\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two sample z-test  \n",
    "Import numpy as np \n",
    "\n",
    "from  scipy import stats \n",
    "\n",
    "stats.ttest_ind(TestSample1, TestSample2)\n",
    "\n",
    "We are looking for two means or two proportions to each other. \n",
    "Difference of two means equations\n",
    "\n",
    "Things we need to have\n",
    "______________________\n",
    "For Means: \n",
    "sample1 and sample2 >= 30\n",
    "and / or\n",
    "we know the pop. std. dev. (S) - as we are checking if they are from the same population\n",
    "\n",
    "For Proportions: \n",
    "if the sample proproptions are greater than 10\n",
    "n (1 - p_naut) > 10 then you do a z-test\n",
    "\n",
    "\n",
    "things we need to not have \n",
    "__________________________\n",
    "if sample < 30\n",
    "but we know our population is normally distributed\n",
    "and we know the population std. dev. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sample z-test example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Import numpy as np \n",
    "from scipy import stats \n",
    "stats.ttest_ind(TestSample1, TestSample2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statsmodels.stats.weightstats.ztest(x1, \n",
    "                                    x2=None, \n",
    "                                    value=0, \n",
    "                                    alternative='two-sided', \n",
    "                                    usevar='pooled', \n",
    "                                    ddof=1.0)\n",
    "\n",
    "so with this we are taking information from the dataframe and we are establishing the \n",
    "\n",
    "https://www.statsmodels.org/stable/generated/statsmodels.stats.weightstats.ztest.html#statsmodels.stats.weightstats.ztest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Proportion Z-Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "When you want to compare the proportions of two sets of variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_proportions_diff(samplem, samplef, sample2):\n",
    "    #Number of sick males and females\n",
    "    sick_males = samplem.value_counts()[1]\n",
    "    sick_females = samplef.value_counts()[1]\n",
    "    #Total males and females\n",
    "    total_male = len(samplem)\n",
    "    total_female = len(samplef)\n",
    "    #probability of sick males and females\n",
    "    p_1 = sick_males / total_male\n",
    "    p_2 = sick_females / total_female\n",
    "    p_bar = sample2.value_counts()[1] / len(sample2)\n",
    "    #Seperating our numerator and denominator                    \n",
    "    numer = (p_1 - p_2)\n",
    "    denom = math.sqrt(((p_bar * (1-p_bar))*((1/total_male)+(1/total_female))))\n",
    "    z_value = numer /denom\n",
    "    p_value = (1 - stats.norm.cdf(z_value))\n",
    "    return z_value, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_proportions_diff(df_male['CHRONIC'], df_female['CHRONIC'], df['CHRONIC'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population Probability Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we want to compare the proportions of two populations samples to see if they are from the \n",
    "same population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_prob_test(sample, p_not):\n",
    "    #Define variables to determine our z value based on the mean equals 4:\n",
    "    n = len(sample)\n",
    "    # Sample mean (xÌ„) using NumPy mean()\n",
    "    p_hat = len(true_pop)/ n\n",
    "    # Sample Standard Deviation (sigma) using Numpy\n",
    "    numer = (p_hat - p_not)\n",
    "    denom = math.sqrt((p_not * (1 - p_not))/n)\n",
    "    z_score = abs(numer/denom)\n",
    "    print(z_score)\n",
    "    p_value = (1 - stats.norm.cdf(z_score)) * 2\n",
    "    z_critical = z = stats.norm.ppf(q = 0.975)\n",
    "    return p_value, abs(z_score) , z_critical, p_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One sample T-Test \n",
    "Import numpy as np \n",
    "\n",
    "from  scipy import stats \n",
    "\n",
    "scipy.stats.ttest_1samp (test sample, popmean=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Sample T-Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pop_mean_test(sample, nullmu, alpha):\n",
    "    #Define variables to determine our z value based on the mean equals 4:\n",
    "    # Sample mean (xÌ„) using NumPy mean()\n",
    "    x_bar = sample.mean()\n",
    "    # Population mean \n",
    "    mu_not = nullmu\n",
    "    # Sample Standard Deviation (sigma) using Numpy\n",
    "    sigma = sample.std()\n",
    "    # Sample size\n",
    "    n = sample.value_counts().sum()\n",
    "    # Degrees of freedom\n",
    "    df = len(sample) - 1 \n",
    "    #Calculate the critical t-value\n",
    "    t_crit = stats.t.ppf(1 - alpha, df=df)\n",
    "    #Calculate the t-value and p-value\n",
    "    results = stats.ttest_1samp(a = sample, popmean = mu_not) \n",
    "    if (results[0]>t_crit) or (results[0]<(-t_crit)) or (results[1]<alpha):\n",
    "        print (\"Null hypothesis rejected. Results are statistically significant with t-value =\", \n",
    "                round(results[0], 2), \"critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 2) * 100, \"%\")\n",
    "    else:\n",
    "        print (\"Null hypothesis is True with t-value =\", \n",
    "                round(results[0], 2), \", critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 10) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two sample t-test \n",
    "Import scipy as stats \n",
    "\n",
    "independent_ttest(data1, data2, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two Sample T-Test Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_variance(sample):\n",
    "    sample_mean = np.mean(sample)\n",
    "    return np.sum((sample - sample_mean) **2)/ (len(sample) -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_variance(sample1, sample2):\n",
    "    n_1, n_2 = len(sample1), len(sample2)\n",
    "    var_1, var_2 = sample_variance(sample1), sample_variance(sample2)\n",
    "    return ((n_1-1) * var_1 + (n_2-1)* var_2)/((n_1 + n_2)-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twosample_tstatistic(expr, ctrl):\n",
    "    exp_mean, ctrl_mean = np.mean(expr), np.mean(ctrl)\n",
    "    pool_var = pooled_variance(expr, ctrl)\n",
    "    n_e, n_c = len(expr), len(ctrl)\n",
    "    num = exp_mean - ctrl_mean\n",
    "    denom = np.sqrt(pool_var * ((1/n_e)+(1/n_c)))\n",
    "    z_value = num / denom\n",
    "    #t = stats.t.ppf(alpha, df=len(sample))\n",
    "    return z_value\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference of 2 means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_two_means(df1, df2, q):\n",
    "    n1 = len(df1)\n",
    "    n2 = len(df2)\n",
    "    x_1 = df1.mean()\n",
    "    x_2 = df2.mean()\n",
    "    s1 = df1.std()\n",
    "    s2 = df2.std()\n",
    "    df1_2 = (n1+n2)-2\n",
    "    # This is for t -value\n",
    "    # If given population standard deveiation use \n",
    "    # z_critical = stats.norm.ppf(q)\n",
    "    t_crit = stats.t.ppf(q, df=df1_2)\n",
    "     # critical value \n",
    "    numer = (x_1 - x_2) - 0\n",
    "    denum = math.sqrt((s1**2/n1)+(s2**2/n2))\n",
    "    delta_mu = numer/denum\n",
    "    results = stats.ttest_ind(df1, df2, axis=0, nan_policy = 'omit', equal_var=False)\n",
    "    p = 1-stats.t.cdf(delta_mu, df=df1_2)\n",
    "    print(results)\n",
    "    print(t_crit)\n",
    "    print(delta_mu)\n",
    "    print(p)\n",
    "    if delta_mu > t_crit or delta_mu < - t_crit :\n",
    "        print (\"We reject null hypothesis. Results are statistically significant with t-value =\", \n",
    "        round(results[0], 2), \"critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 10))\n",
    "    else:\n",
    "        print (\"We fail to reject the null hypothesis. Results are statistically insignifcant with t-value ==\", \n",
    "        round(results[0], 2), \", critical t-value =\", t_crit, \"and p-value =\", np.round((results[1]), 10))\n",
    "diff_two_means(df_dom['gross'], df_foreign['gross'], .975)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Interval Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conf_interval(sample):\n",
    "    \"\"\"\n",
    "    Function input: population, sample\n",
    "    Function output: z-critical, Margin of Error, Confidence Interval\n",
    "    \"\"\"\n",
    "\n",
    "    sample_size = len(sample)\n",
    "    x_hat = sample.mean()\n",
    "    # Calculate the z-critical value using stats.norm.ppf()\n",
    "    # Note that we use stats.norm.pff(q = 0.0975) to get the desired z-critical value\n",
    "    # Instead of q = 0.95 because the distribution has two tails\n",
    "\n",
    "    z = stats.norm.ppf(q = 0.975)\n",
    "\n",
    "    # Calculate the population std from data\n",
    "    stdev = sample.std()\n",
    "\n",
    "    # Calculate the margin of error using formula given above\n",
    "    moe = z * (stdev/math.sqrt(sample_size))\n",
    "\n",
    "\n",
    "    conf = (x_hat - moe, x_hat + moe)\n",
    "\n",
    "    return z, moe, conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PPF and CDF to get P-values and T-crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ppf is used when needed to transcribe % to critical value \n",
    "\n",
    "t_crit = stats.t.ppf(1 - alpha, df=df)\n",
    "\n",
    "z_critical = stats.norm.ppf(q)\n",
    "\n",
    "cdf is used when needed to transcribe critical value to %\n",
    "\n",
    "p_value = stats.norm.cdf(z)*2 #Only if it is 2 tailed\n",
    "\n",
    "#if z score is negative we have a left tailed test and subtract from 1\n",
    "\n",
    "#if z score is positive we have a right tailed test we leave as is\n",
    "\n",
    "# can not have a value over 1\n",
    "Example: \n",
    "    #This is for a right sided test in this case\n",
    "    alpha = 0.05\n",
    "    cv = st.ppf(1.0 - alpha, df)\n",
    "    p = (1.0 - st.cdf(abs(t_stat), df)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Is there a statistically significant difference between men and women in the number of days a person feels phsyically ill?\n",
    "#Create variables\n",
    "map_sex = {1:'Male',  2: 'Female', 9: np.nan}\n",
    "df['SEX'] = df['SEX'].replace(map_sex)\n",
    "fem = df.groupby('SEX')['physical_health'].get_group('Female')\n",
    "mal = df.groupby('SEX')['physical_health'].get_group('Male') \n",
    "#import needed packages\n",
    "from scipy.stats import t as st\n",
    "#define function for two sample t-test (two tailed)\n",
    "def independent_ttest(data1, data2, alpha):\n",
    "# calculate needed numbers for samples\n",
    "    mean1, mean2 = np.mean(data1), np.mean(data2)\n",
    "    std1, std2 = np.std(data1, ddof=1), np.std(data2, ddof=1)\n",
    "    n1, n2 = len(data1), len(data2)\n",
    "    se1, se2 = std1/math.sqrt(n1), std2/math.sqrt(n2)\n",
    "# calculate standard error, test stat, and degrees of freedom\n",
    "    sed = math.sqrt(se1**2.0 + se2**2.0)\n",
    "    t_stat = (mean1 - mean2) / sed\n",
    "    df = min(len(data1), len(data2)) - 1\n",
    "# calculate the critical value and p-value\n",
    "    alpha = 0.05\n",
    "    cv = st.ppf(1.0 - alpha, df)\n",
    "    p = (1.0 - st.cdf(abs(t_stat), df)) \n",
    "# return everything\n",
    "    return t_stat, cv, p\n",
    "independent_ttest(fem,mal,0.05) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Goal: To find a relationship between an independent variable and the target variable. \n",
    "We want to make models that explain that relationship.\n",
    "  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7ac5d6b234e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#if you just want to see the correlation of 2 columns do this\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdf1_corr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mpg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'weight'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mdf1_corr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "1) If you want to see correlations between items before you jump do \n",
    "\n",
    "corr = df.corr()\n",
    "corr\n",
    "\n",
    "2) if you just want to see the correlation of 2 columns do this\n",
    "\n",
    "df1_corr = df[['mpg', 'weight']].corr()\n",
    "df1_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We use this to find the correlation between the given column with every other column\n",
    "\n",
    "df[df.columns[:]].corr()['gross'][:]\n",
    "\n",
    "the first [:] helps split the x-axis going from left to right\n",
    "the second [:] helps split the y-axis going from top to bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This is to setup the heat map of the correlations to understand it visually.\n",
    "\n",
    "import seaborn as sns\n",
    "plt.style.use('seaborn')\n",
    "sns.set(style=\"white\")\n",
    "# Set up  matplotlib figure (might have to play around with the \n",
    "# figsize if your labels aren't so legible and you don't want\n",
    "# to mess with the labels using matplotlib)\n",
    "f, ax = plt.subplots(figsize=(10, 9))\n",
    "# Create an upper triangular matrix to use to get rid of duplicate/\n",
    "# useless values\n",
    "mask = np.zeros_like(df.corr())\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "# plot the heatmap\n",
    "with sns.axes_style(\"white\"):\n",
    "    ax = sns.heatmap(df.corr(), mask=mask, square=True)\n",
    "# fix for mpl bug that cuts off top/bottom of seaborn viz\n",
    "# credit: https://github.com/mwaskom/seaborn/issues/1773 SalMac86's post\n",
    "b, t = plt.ylim() # discover the values for bottom and top\n",
    "b += 0.5 # Add 0.5 to the bottom\n",
    "t -= 0.5 # Subtract 0.5 from the top\n",
    "plt.ylim(b, t) # update the ylim(bottom, top) values\n",
    "plt.show() # ta-da!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "slr_model = ols(formula='mpg~weight', data=df).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the SLR model, and take the one variable (which is your dependent variable) and \n",
    "compare against your other independent variables.\n",
    ".fit() is for ....\n",
    "How do we change conf interval we add (alpha = 0.05) in the slr_model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slr_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlr_model = ols(formula='mpg~weight+horsepower+displacement', data=df).fit()\n",
    "\n",
    "mlr_model.summary(alpha = 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We setup our formula (Y- is the 'mpg' in this case) every variable after the ~ is\n",
    "the independent variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R-squared - \n",
    "How much of the model explains the variation is from the line\n",
    "How close the data is fitted to the regression line\n",
    "\n",
    "if we get 0.139 that means our model explains 13.9% of the data\n",
    "\n",
    "0 - indicates that the model explains none of the variability of the response data around its mean. \n",
    "\n",
    "1 - indicates that the model explains all the variability of the response data around its mean.\n",
    "\n",
    "(If you get a 1, that means your dependent variable is inside your independent variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adj. R-squared -\n",
    "takes into account the ammount of variables in our model. It is a more accurate way to \n",
    "\n",
    "guage it as if more data is added and this number drops, the data added is not applicable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prob (F-statistic) - \n",
    "If probability is below 0.05 (p-value) we will use that variable within our model. \n",
    "\n",
    "If we are doing a simple linear regression we are going to reject the null hypothesis. \n",
    "\n",
    "If the p-value is greater than 0.05 we will fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coef - \n",
    "It is the \"rise over run\" of how much the independent chances the dependent variable \n",
    "holding all other variables equal / constant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Std Err - \n",
    "Standard error is the approx. std. dev. of the sample. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### T - \n",
    "This is the critical variable for the independent variable and it helps us calc \n",
    "confidence interval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P > |t| -\n",
    "\n",
    "We are looking for the lowest number possible to show that is statistically significant. \n",
    "\n",
    "Is our p value less than 0.05? \n",
    "\n",
    "There is 95% confident that this particular variable ['independent_variable'] is \n",
    "correlated with the ['dependent_variable']\n",
    "\n",
    "If our p value is more than 0.05?\n",
    "\n",
    "There is 95% confident that this particular variable ['independent_variable'] is NOT\n",
    "correlated with the ['dependent_variable']\n",
    "\n",
    "If more than 0.05 we have low confidence that it impacts the model\n",
    "\n",
    "These columns provide the t-value and 2-tailed p-value used in testing the null hypothesis that the coefficient (parameter) is 0. If you use a 2-tailed test, then you would compare each p-value to your pre-selected value of alpha. Coefficients having p-values less than alpha are statistically significant. For example, if you chose alpha to be 0.05, coefficients having a p-value of 0.05 or less would be statistically significant (i.e., you can reject the null hypothesis and say that the coefficient is significantly different from 0). If you use a 1-tailed test (i.e., you hypothesize that the parameter will go in a particular direction), then you can divide the p-value by 2 before comparing it to your pre-selected alpha level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [0.025     0.975] - \n",
    "\n",
    "Margin of error around the mean of a two tailed test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Linearity**: The relationship between $X$ and $Y$ must be linear.\n",
    "    - Check this assumption by examining a scatterplot of x and y.\n",
    "\n",
    "\n",
    "2. **Independence of errors**: There is not a relationship between the residuals and the $Y$ variable; in other words, $Y$ is independent of errors.\n",
    "    - Check this assumption by examining a scatterplot of â€œresiduals versus fitsâ€; the correlation should be approximately 0. In other words, there should not look like there is a relationship.\n",
    "\n",
    "\n",
    "3. **Normality of errors**: The residuals must be approximately normally distributed.\n",
    "    - Check this assumption by examining a normal probability plot; the observations should be near the line. You can also examine a histogram of the residuals; it should be approximately normally distributed.\n",
    "\n",
    "\n",
    "4. **Equal variances**: The variance of the residuals is the same for all values of $X$.\n",
    "    - Check this assumption by examining the scatterplot of â€œresiduals versus fitsâ€; the variance of the residuals should be the same across all values of the x-axis. If the plot shows a pattern (e.g., bowtie or megaphone shape), then variances are not consistent, and this assumption has not been met."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* What exactly is a z-score \n",
    "    * The number of stds a single data point is above or below the mean \n",
    "* What exactly is a t-score \n",
    "    * A t-score is basically the same thing but accounts for the fact that we know less about the distribution due usually a low sample size or not knowing population std  \n",
    "* A z, t, or F measures extremeness in terms of distance from the mean. \n",
    "* What is a p-value  \n",
    "    *  The probability of getting a result at least as extreme as the sample  assuming the null hypothesis is true. That is to say the probability that you got that result entirely due to chance with null hypothesis true.  \n",
    "    * Assuming you null hypothesis is true what are the chance this (or something at least this extreme) even occurred. \n",
    "* What is an alpha  \n",
    "    * The cut off probability below which we reject a null hypothesis and therefore conclude that the sample did not occur by chance \n",
    "* An ANOVA is a test for 3 or more means (and therefore the sample) to test whether the the means are statistically significantly difference.  \n",
    "    * An anova seeks to find whether the sample are from the same population \n",
    "* A two sample t-test test the means for statistically difference \n",
    "* A one sample t-test (or z-test) tries to determine whether a sample mean is equal to the population  \n",
    "* PR(>F) is the probability of getting a result at least as extreme as the one the F-score represents. This is your p-value. \n",
    "* P-hat is the proportion of the sample that met the condition  \n",
    "* What is happening in chi squared is I am comparing three sample proportions and determine whether they are all the same statistically and therefore part of the same population "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming we have a dataset with many rows, columns, and NaN\n",
    "We want to first check if the columns we care about have NaN values and clean them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1) Knowing your column names\n",
    "\n",
    "# Get column names\n",
    "column_names = df.columns\n",
    "print(column_names)\n",
    "# Get column data types\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "2) Converting column types to intergers or float64\n",
    "# astype(float) method\n",
    "\n",
    "df['DataFrame Column'] = df['DataFrame Column'].astype(float) \n",
    "\n",
    "#to_numeric method\n",
    "\n",
    "df['DataFrame Column'] = pd.to_numeric(df['DataFrame Column'],errors='coerce')\n",
    "\n",
    "What is the difference in these two methods?\n",
    "\n",
    "(1) For a column that contains numeric values stored as strings;\n",
    "\n",
    "(2) For a column that contains both numeric and non-numeric values. \n",
    "By setting errors=â€™coerceâ€™, youâ€™ll transform the non-numeric values into NaN.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3) To Drop multiple columsn\n",
    "\n",
    "df.drop(columns=['aspect_ratio', 'plot_keywords', 'movie_facebook_likes', 'genres'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4) To Drope multiple rows\n",
    "\n",
    "df.drop([0,1,2,3], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5) Finding the shape of the df\n",
    "\n",
    "df.shape #to see the number of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6) finding NaN in a column\n",
    "\n",
    "df['gross'].isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7) creating a new df with the NaN dropped in a specific column\n",
    "\n",
    "we then can set a new variable for a dataframe where it is \n",
    "df1 = df.dropna(subset = ['gross'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we need to get movies made after 2000 and have a rating of \"R\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8) How to get a df with specific returns\n",
    "df1 = df[(df['title_year'] >= 2000.0) & (df['content_rating'] == 'R')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baysian Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1) ID the questions (postieror) in terms of P(A|B)\n",
    "\n",
    "2) Understand what is given (prior / likeihood / marginal likeihood) \n",
    "\n",
    "3) if you are missing one of the figures how to determine to solve for it\n",
    "\n",
    "4) solve\n",
    "\n",
    "Key words like \"When\" are synonomous with \"Given\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "There are two ways\n",
    "\n",
    "We either have \n",
    "\n",
    "P_a_given_b =  ( P_b_given_a  * P_a ) /  P_b \n",
    "\n",
    "or (depending on how much informaton we have)\n",
    "\n",
    "P_a_given_b =  ( P_b_given_a  * P_a ) /  (P_a * P_b_given_a) + (P_not_a * P_b_given_not_a) \n",
    "\n",
    "or (When we have )\n",
    "\n",
    "P_b_given_a =  ( P_a_given_b * P_b) /  P_a "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An advertising executive is studying television viewing habits of married men and women during prime time hours. Based on the past viewing records he has determined that during prime time wives are watching television 60% of the time. It has also been determined that when the wife is watching television, 40% of the time the husband is also watching. When the wife is not watching the television, 30% of the time the husband is watching the television. Find the probability that if the husband is watching the television, the wife is also watching the television."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P_a = 0.60 #P(A) The probability that wife is watching television\n",
    "P_b = #P(B) The probability the the husband is watching.\n",
    "P_b_given_a = 0.40 #P(B|A) The probability that the husband is watching given the wife is watching\n",
    "P_a_given_b =   #P(A|B) The probability that wife (that the wife is watching) given husband (that the husband is watching)\n",
    "\n",
    "P_not_a = 0.40           The prob that the wife is not watching tv\n",
    "P_b_given_not_a = 0.30   The husband is watching given that wife is not watching tv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_a = 0.60 #wife watching tv\n",
    "P_b = ? # looking for\n",
    "P_b = (.60 * .40) + (.40 * .30) \n",
    "P_b = (P_a * P_b_given_a) + (P_not_a * P_b_given_not_a) \n",
    "P_b_given_a = 0.40 # Husband watching given that wife is watching\n",
    "P_a_given_b = ? #looking for\n",
    "P_a_given_b = 57.14%\n",
    "\n",
    "# 1) 60% of the time wives are watching tv, P_not_a = 0.40\n",
    "# 2) Now .\n",
    "\n",
    "P_a_given_b =  ( P_b_given_a  * P_a ) /  P_b \n",
    "\n",
    "P_a_given_b = (0.40 * 0.60) / (.36)\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type 1 Error & Type 2 Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Type 1 error - When you reject the null hypothesis incorrectly, A False Positive. Probabilty of rejecting the null hypothesis when the null hypothesis is, in fact true\n",
    "\n",
    "Type 2 error - When you fail to reject the null hypothesis incorrectly, A False Negative. Probabilty of failing to rejecting the null hypothesis when the null hypothesis is, in fact false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph to visualize rejection regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_t(t_stat, n_control, n_experimental):\n",
    "    â€œâ€\"\n",
    "    Visualize the critical t values on a t distribution\n",
    "    Parameters\n",
    "    -----------\n",
    "    t-stat: float\n",
    "    n_control: int\n",
    "    n_experiment: int\n",
    "    Returns\n",
    "    ----------\n",
    "    None\n",
    "    â€œâ€\"\n",
    "    # initialize a matplotlib â€œfigureâ€\n",
    "    fig = plt.figure(figsize=(8,5))\n",
    "    ax = fig.gca()\n",
    "    # generate points on the x axis between -8 and 8:\n",
    "    xs = np.linspace(-8, 8, 500)\n",
    "    # use stats.t.ppf to get critical value. For alpha = 0.05 and two tailed test\n",
    "    crit = stats.t.ppf(1-0.025, (n_control+n_experimental-2))\n",
    "    # use stats.t.pdf to get values on the probability density function for the t-distribution\n",
    "    ys= stats.t.pdf(xs, (n_control+n_experimental-2), 0, 1)\n",
    "    ax.plot(xs, ys, linewidth=3, color=â€˜darkredâ€™)\n",
    "    ax.axvline(crit, color=â€˜blackâ€™, linestyle=â€˜--â€™, lw=5)\n",
    "    ax.axvline(-crit, color=â€˜blackâ€™, linestyle=â€˜--â€™, lw=5)\n",
    "    plt.show()\n",
    "    return None\n",
    "visualize_t(t_stat, len(mm), len(ff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
